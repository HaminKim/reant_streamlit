# combine_data.py
# data/reYYYYMMDD.xls(x) ë“¤ì„ ì½ì–´ì„œ processed/all_data.csvì— "ëˆ„ì "
# - processed/all_data.csvê°€ ìˆìœ¼ë©´: ìƒˆ ë‚ ì§œë§Œ ì¶”ê°€
# - ê°™ì€ ë‚ ì§œ íŒŒì¼ì´ ë‹¤ì‹œ ë“¤ì–´ì˜¤ë©´: ê·¸ ë‚ ì§œ ë°ì´í„°ëŠ” ë®ì–´ì“°ê¸°(ê¸°ì¡´ ë‚ ì§œ í–‰ ì‚­ì œ í›„ ì¶”ê°€)
# - í‘œê°€ ì•„ë‹Œ íŒŒì¼(ì•ˆë‚´/ì—ëŸ¬ë¡œ ì €ì¥ëœ xls)ì€ ìŠ¤í‚µ
# - ìƒˆë¡œ ë³‘í•©í•  ìœ íš¨ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì‹¤íŒ¨í•˜ì§€ ì•Šê³  ì¢…ë£Œ(ì„±ê³µ)

from pathlib import Path
import pandas as pd

BASE = Path(__file__).resolve().parent
DATA_DIR = BASE / "data"
OUT_DIR = BASE / "processed"
OUT_DIR.mkdir(parents=True, exist_ok=True)

OUT_PATH = OUT_DIR / "all_data.csv"

print("ğŸ“Š ë°ì´í„° ë³‘í•©(ì¦ë¶„ ëˆ„ì ) ì‹œì‘...\n")

if not DATA_DIR.exists():
    print(f"âŒ data í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {DATA_DIR}")
    raise SystemExit(1)

# 1) ê¸°ì¡´ ëˆ„ì  ë°ì´í„° ë¡œë“œ (ìˆìœ¼ë©´)
if OUT_PATH.exists():
    old = pd.read_csv(
        OUT_PATH,
        parse_dates=["ë‚ ì§œ"],
        encoding="utf-8-sig",
        dtype={"ì¢…ëª©ëª…": "string"},
    )
    print(f"ğŸ“Œ ê¸°ì¡´ ëˆ„ì  ë¡œë“œ: {OUT_PATH.name} (rows={len(old):,})")
else:
    old = pd.DataFrame(columns=["ì¢…ëª©ëª…", "ë§¤ìˆ˜", "ë§¤ë„", "ìˆœë§¤ìˆ˜", "ë‚ ì§œ"])
    print("ğŸ“Œ ê¸°ì¡´ ëˆ„ì  ì—†ìŒ: ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

# 2) data í´ë”ì—ì„œ íŒŒì¼ ì½ê¸° â†’ ë‚ ì§œë³„ DF ë§Œë“¤ê¸°
new_dfs = []
new_dates = set()

files = sorted([p for p in DATA_DIR.iterdir() if p.suffix.lower() in (".xls", ".xlsx")])
if not files:
    # âœ… ì•¡ì…˜ì—ì„œ ë‹¤ìš´ë¡œë”ê°€ ì €ì¥ ì•ˆ í–ˆì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ, ì‹¤íŒ¨ ë§ê³  ì„±ê³µ ì¢…ë£Œ
    print("â„¹ï¸ data í´ë”ì— xls/xlsx íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨/íœ´ì¼ ê°€ëŠ¥) â†’ ì¢…ë£Œ(ì„±ê³µ)")
    raise SystemExit(0)

for file in files:
    date_str = file.stem.replace("re", "")  # reYYYYMMDD
    try:
        dt = pd.to_datetime(date_str, format="%Y%m%d", errors="coerce")
        if pd.isna(dt):
            print(f"âš ï¸ ìŠ¤í‚µ: {file.name} â†’ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨({date_str})")
            continue

        # âœ… í‘œ ì½ê¸°
        tables = pd.read_html(str(file), header=0, flavor="lxml")
        if not tables:
            print(f"âš ï¸ ìŠ¤í‚µ: {file.name} â†’ í‘œë¥¼ ì°¾ì§€ ëª»í•¨(ì•ˆë‚´/ì—ëŸ¬ í˜ì´ì§€ ê°€ëŠ¥)")
            continue
        df = tables[0]

        # âœ… í‘œ í˜•ì‹ ì•„ë‹ˆë©´ ìŠ¤í‚µ (ì—´ ë¶€ì¡±)
        if df.shape[1] < 6:
            print(f"âš ï¸ ìŠ¤í‚µ: {file.name} â†’ ì—´ ìˆ˜ ë¶€ì¡±({df.shape[1]}). (ì•ˆë‚´/ì—ëŸ¬ í˜ì´ì§€ì¼ ê°€ëŠ¥ì„±)")
            continue

        df = df.iloc[:, [3, 4, 5]].copy()
        df.columns = ["ì¢…ëª©ëª…", "ë§¤ìˆ˜", "ë§¤ë„"]

        # ìˆ«ì ë³€í™˜
        for c in ["ë§¤ìˆ˜", "ë§¤ë„"]:
            df[c] = (
                df[c].astype(str)
                .str.replace(",", "", regex=False)
                .str.replace(" ", "", regex=False)
            )
            df[c] = pd.to_numeric(df[c], errors="coerce")

        # âœ… ì¢…ëª©ëª… ë¹„ì–´ìˆëŠ” í–‰ ì œê±° (ê°€ë” í—¤ë”/ë¹ˆì¤„ ì„ì„ ë°©ì§€)
        df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].astype("string").str.strip()
        df = df.dropna(subset=["ì¢…ëª©ëª…"])
        df = df[df["ì¢…ëª©ëª…"] != ""]

        df["ìˆœë§¤ìˆ˜"] = df["ë§¤ìˆ˜"] - df["ë§¤ë„"]
        df["ë‚ ì§œ"] = dt.normalize()

        # âœ… ëª¨ë‘ NaNì´ë©´(ì‹¤ì œ ë°ì´í„° ì—†ìŒ) ìŠ¤í‚µ
        if df[["ë§¤ìˆ˜", "ë§¤ë„", "ìˆœë§¤ìˆ˜"]].isna().all().all():
            print(f"âš ï¸ ìŠ¤í‚µ: {file.name} â†’ ìˆ˜ì¹˜ ë°ì´í„°ê°€ ì „ë¶€ ë¹„ì–´ìˆìŒ(ì•ˆë‚´/ë¹ˆ ë°ì´í„° ê°€ëŠ¥)")
            continue

        new_dfs.append(df)
        new_dates.add(dt.normalize())

        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {file.name} ({len(df)}í–‰)")

    except Exception as e:
        print(f"âš ï¸ ìŠ¤í‚µ: {file.name} â†’ {e}")

# âœ… ìœ íš¨ ìƒˆ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì‹¤íŒ¨í•˜ì§€ ë§ê³  ì„±ê³µ ì¢…ë£Œ
if not new_dfs:
    print("\nâ„¹ï¸ ìƒˆë¡œ ë³‘í•©í•  ìœ íš¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì£¼ë§/íœ´ì¼/ì‚¬ì´íŠ¸ ì‘ë‹µ ë¬¸ì œ ê°€ëŠ¥) â†’ ì¢…ë£Œ(ì„±ê³µ)")
    raise SystemExit(0)

new_data = pd.concat(new_dfs, ignore_index=True)

# 3) ê°™ì€ ë‚ ì§œëŠ” â€œë®ì–´ì“°ê¸°â€ (ê¸°ì¡´ì—ì„œ í•´ë‹¹ ë‚ ì§œ ì œê±° í›„ append)
if len(old) > 0:
    old["ë‚ ì§œ"] = pd.to_datetime(old["ë‚ ì§œ"], errors="coerce").dt.normalize()
    mask_keep = ~old["ë‚ ì§œ"].isin(new_dates)
    removed = len(old) - int(mask_keep.sum())
    old = old.loc[mask_keep].copy()
    if removed:
        print(f"ğŸ§¹ ë®ì–´ì“°ê¸°: ê¸°ì¡´ ë°ì´í„°ì—ì„œ ë™ì¼ ë‚ ì§œ í–‰ {removed:,}ê°œ ì œê±°")

# 4) í•©ì¹˜ê³  ì €ì¥
merged = pd.concat([old, new_data], ignore_index=True)

merged["ì¢…ëª©ëª…"] = merged["ì¢…ëª©ëª…"].astype("string").str.strip()
merged["ë‚ ì§œ"] = pd.to_datetime(merged["ë‚ ì§œ"], errors="coerce").dt.normalize()

merged = merged.dropna(subset=["ë‚ ì§œ", "ì¢…ëª©ëª…"])
merged = merged.sort_values(["ë‚ ì§œ", "ì¢…ëª©ëª…"]).reset_index(drop=True)

merged.to_csv(OUT_PATH, index=False, encoding="utf-8-sig")

print(f"\nğŸ‰ ëˆ„ì  ë³‘í•© ì™„ë£Œ! ì´ {len(merged):,}í–‰ â†’ {OUT_PATH} ì €ì¥")
print(f"ğŸ†• ì´ë²ˆì— ë°˜ì˜í•œ ë‚ ì§œ ìˆ˜: {len(new_dates)}ê°œ")
